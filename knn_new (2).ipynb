{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "69bc57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d0ebcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('dtsurat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "539295e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "import re, string, unicodedata\n",
    "from string import punctuation\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding, Activation, Dropout, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from nltk.probability import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9a1324fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Surat Keterangan sebagai Dosen Pembimbing\n",
       "1        Surat Tugas LKTIA - Dr. Fitri Indriani, M.Pd.I.\n",
       "2                              Surat Tugas LKMM Menengah\n",
       "3                   Surat Tugas Kegiatan Tanggap Bencana\n",
       "4           Surat Tugas Tim Piket Posko Tanggep Bencana \n",
       "                             ...                        \n",
       "96          Surat Permohonan Pasang Iklan Lowongan - UAD\n",
       "97         Surat Permohonan Beasiswa Karya FSBK Mei 2022\n",
       "98                     Surat Permintaan Barang - BEM UAD\n",
       "99                         Surat Permohonan Kepengurusan\n",
       "100    Surat Permohonan Penerbitan SK Kepengurusan BE...\n",
       "Name: judul_surat, Length: 101, dtype: object"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['judul_surat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4acb912c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding Result : \n",
      "\n",
      "0          surat keterangan sebagai dosen pembimbing\n",
      "1    surat tugas lktia - dr. fitri indriani, m.pd.i.\n",
      "2                          surat tugas lkmm menengah\n",
      "3               surat tugas kegiatan tanggap bencana\n",
      "4       surat tugas tim piket posko tanggep bencana \n",
      "Name: judul_surat, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case folding\n",
    "data['judul_surat'] = data['judul_surat'].str.lower()\n",
    "\n",
    "\n",
    "print('Case Folding Result : \\n')\n",
    "print(data['judul_surat'].head(5))\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0068521f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Result : \n",
      "\n",
      "0      [surat, keterangan, sebagai, dosen, pembimbing]\n",
      "1     [surat, tugas, lktia, dr, fitri, indriani, mpdi]\n",
      "2                       [surat, tugas, lkmm, menengah]\n",
      "3           [surat, tugas, kegiatan, tanggap, bencana]\n",
      "4    [surat, tugas, tim, piket, posko, tanggep, ben...\n",
      "Name: judul_surat_tokens, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_special(text):\n",
    "    # remove tab, new line, ans back slice\n",
    "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "    # remove non ASCII (emoticon, chinese word, .etc)\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    # remove mention, link, hashtag\n",
    "    text = ' '.join(re.sub(\"([@#][A-Za-z]+.-)|(\\w+:\\/\\/\\S+.-)\",\" \", text).split())\n",
    "    # remove incomplete URL\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "\n",
    "data['judul_surat'] = data['judul_surat'].apply(remove_special)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "data['judul_surat'] = data['judul_surat'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "data['judul_surat'] = data['judul_surat'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "data['judul_surat'] = data['judul_surat'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "data['judul_surat'] = data['judul_surat'].apply(remove_singl_char)\n",
    "\n",
    "# NLTK word rokenize \n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "data['judul_surat_tokens'] = data['judul_surat'].apply(word_tokenize_wrapper)\n",
    "\n",
    "print('Tokenizing Result : \\n') \n",
    "print(data['judul_surat_tokens'].head())\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "3015242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Tokens : \n",
      "\n",
      "0    [(surat, 1), (keterangan, 1), (sebagai, 1), (d...\n",
      "1    [(surat, 1), (tugas, 1), (lktia, 1), (dr, 1), ...\n",
      "2    [(surat, 1), (tugas, 1), (lkmm, 1), (menengah,...\n",
      "3    [(surat, 1), (tugas, 1), (kegiatan, 1), (tangg...\n",
      "4    [(surat, 1), (tugas, 1), (tim, 1), (piket, 1),...\n",
      "Name: judul_tokens_fdist, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def freqDist_wrapper(text):\n",
    "    return FreqDist(text)\n",
    "\n",
    "data['judul_tokens_fdist'] = data['judul_surat_tokens'].apply(freqDist_wrapper)\n",
    "\n",
    "print('Frequency Tokens : \\n') \n",
    "print(data['judul_tokens_fdist'].head().apply(lambda x : x.most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "dd0f7aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               [surat, keterangan, dosen, pembimbing]\n",
      "1         [surat, tugas, lktia, fitri, indriani, mpdi]\n",
      "2                       [surat, tugas, lkmm, menengah]\n",
      "3           [surat, tugas, kegiatan, tanggap, bencana]\n",
      "4    [surat, tugas, tim, piket, posko, tanggep, ben...\n",
      "Name: judul_tokens_WSW, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- get stopword from NLTK stopword -------------------------------\n",
    "# get stopword indonesia\n",
    "list_stopwords = stopwords.words('indonesian')\n",
    "\n",
    "\n",
    "# ---------------------------- manualy add stopword  ------------------------------------\n",
    "# append additional stopword\n",
    "list_stopwords.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', \n",
    "                       'kalo', 'amp', 'biar', 'bikin', 'bilang', \n",
    "                       'gak', 'ga', 'krn', 'nya', 'nih', 'sih', \n",
    "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', \n",
    "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't', \n",
    "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
    "                       '&amp', 'yah'])\n",
    "\n",
    "# ----------------------- add stopword from txt file ------------------------------------\n",
    "# read txt stopword using pandas\n",
    "txt_stopword = pd.read_csv(\"stopword.txt\", names= [\"stopwords\"], header = None)\n",
    "\n",
    "# convert stopword string to list & append additional stopword\n",
    "list_stopwords.extend(txt_stopword[\"stopwords\"][0].split(' '))\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "# convert list to dictionary\n",
    "list_stopwords = set(list_stopwords)\n",
    "\n",
    "\n",
    "#remove stopword pada list token\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "\n",
    "data['judul_tokens_WSW'] = data['judul_surat_tokens'].apply(stopwords_removal) \n",
    "\n",
    "\n",
    "print(data['judul_tokens_WSW'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "88a33e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "------------------------\n",
      "surat : surat\n",
      "keterangan : terang\n",
      "dosen : dosen\n",
      "pembimbing : bimbing\n",
      "tugas : tugas\n",
      "lktia : lktia\n",
      "fitri : fitri\n",
      "indriani : indriani\n",
      "mpdi : mpdi\n",
      "lkmm : lkmm\n",
      "menengah : tengah\n",
      "kegiatan : giat\n",
      "tanggap : tanggap\n",
      "bencana : bencana\n",
      "tim : tim\n",
      "piket : piket\n",
      "posko : posko\n",
      "tanggep : tanggep\n",
      "permohonan : mohon\n",
      "izin : izin\n",
      "uad : uad\n",
      "awards : awards\n",
      "bidang : bidang\n",
      "kemahasiswaan : mahasiswa\n",
      "alumni : alumni\n",
      "pelatihan : latih\n",
      "pembinaan : bina\n",
      "kbmk : kbmk\n",
      "2021 : 2021\n",
      "lidm : lidm\n",
      "php2d : php2d\n",
      "bem : bem\n",
      "fti : fti\n",
      "imm : imm\n",
      "farmasi : farmasi\n",
      "umm : umm\n",
      "championship : championship\n",
      "pencak : pencak\n",
      "silat : silat\n",
      "virtual : virtual\n",
      "panitia : panitia\n",
      "por : por\n",
      "bapomi : bapomi\n",
      "diy : diy\n",
      "lomba : lomba\n",
      "11th : 11th\n",
      "airlangga : airlangga\n",
      "tapak : tapak\n",
      "suci : suci\n",
      "international : international\n",
      "open : open\n",
      "bakti : bakti\n",
      "formica : formica\n",
      "bangsa : bangsa\n",
      "sosialisasi : sosialisasi\n",
      "anti : anti\n",
      "intoleransi : intoleransi\n",
      "kekerasan : keras\n",
      "seksual : seksual\n",
      "perundungan : rundung\n",
      "tahap : tahap\n",
      "kotnes : kotnes\n",
      "robot : robot\n",
      "rscuad : rscuad\n",
      "kontes : kontes\n",
      "lanange : lanange\n",
      "jagad : jagad\n",
      "aljazari : aljazari\n",
      "pkm : pkm\n",
      "aub : aub\n",
      "cup : cup\n",
      "1 : 1\n",
      "jatengdiy : jatengdiy\n",
      "peminjaman : pinjam\n",
      "ruangan : ruang\n",
      "rapat : rapat\n",
      "pengurus : urus\n",
      "puspresma : puspresma\n",
      "ptma : ptma\n",
      "inovasi : inovasi\n",
      "program : program\n",
      "pemberdayaan : daya\n",
      "pembangunan : bangun\n",
      "desa : desa\n",
      "lip3d : lip3d\n",
      "3 : 3\n",
      "2 : 2\n",
      "imss : imss\n",
      "selma : selma\n",
      "thalia : thalia\n",
      "mtqmn : mtqmn\n",
      "uny : uny\n",
      "198 : 198\n",
      "kreativitas : kreativitas\n",
      "mahasiswa : mahasiswa\n",
      "2022 : 2022\n",
      "pembuatan : buat\n",
      "sop : sop\n",
      "permintaan : minta\n",
      "barang : barang\n",
      "dpm : dpm\n",
      "festival : festival\n",
      "nasional : nasional\n",
      "alquran : alquran\n",
      "hadits : hadits\n",
      "survey : survey\n",
      "lapangan : lapang\n",
      "pendidikan : didik\n",
      "anggota : anggota\n",
      "muda : muda\n",
      "madapala : madapala\n",
      "angkatan : angkat\n",
      "xxvi : xxvi\n",
      "pembina : bina\n",
      "center : center\n",
      "ruang : ruang\n",
      "fsbk : fsbk\n",
      "kejuaraan : juara\n",
      "bengawan : bengawan\n",
      "solo : solo\n",
      "national : national\n",
      "turnamen : turnamen\n",
      "ingco : ingco\n",
      "bola : bola\n",
      "voli : voli\n",
      "perbaikan : baik\n",
      "peralatan : alat\n",
      "ukm : ukm\n",
      "kopma : kopma\n",
      "kampus : kampus\n",
      "4 : 4\n",
      "peningkatan : tingkat\n",
      "kapasitas : kapasitas\n",
      "organisasi : organisasi\n",
      "ppk : ppk\n",
      "ormawa : ormawa\n",
      "penyusun : susun\n",
      "proposal : proposal\n",
      "gending : gending\n",
      "bahana : bahana\n",
      "community : community\n",
      "criminal : criminal\n",
      "law : law\n",
      "study : study\n",
      "inventaris : inventaris\n",
      "alat : alat\n",
      "sepak : sepak\n",
      "indonesia : indonesia\n",
      "krsbi : krsbi\n",
      "firex : firex\n",
      "pendampingan : damping\n",
      "fast : fast\n",
      "rekomendasi : rekomendasi\n",
      "kpum : kpum\n",
      "fai : fai\n",
      "akses : akses\n",
      "24 : 24\n",
      "jam : jam\n",
      "transportasi : transportasi\n",
      "halaman : halaman\n",
      "parkiran : parkir\n",
      "utara : utara\n",
      "mkmu : mkmu\n",
      "konferensi : konferensi\n",
      "sosiologi : sosiologi\n",
      "ix : ix\n",
      "nona : nona\n",
      "carolina : carolina\n",
      "pengelola : kelola\n",
      "pendanaan : dana\n",
      "kemdikbud : kemdikbud\n",
      "pesta : pesta\n",
      "olahraga : olahraga\n",
      "perguruan : guru\n",
      "seindonesia : indonesia\n",
      "dasar : dasar\n",
      "resimen : resimen\n",
      "mahakarta : mahakarta\n",
      "menwa : menwa\n",
      "poros : poros\n",
      "seleksi : seleksi\n",
      "internal : internal\n",
      "mahassiwa : mahassiwa\n",
      "wirausaha : wirausaha\n",
      "p2mw : p2mw\n",
      "sagotra : sagotra\n",
      "turgas : turgas\n",
      "cabang : cabang\n",
      "futsal : futsal\n",
      "andalan : andal\n",
      "rekrutmen : rekrutmen\n",
      "pendampignan : pendampignan\n",
      "gemastik : gemastik\n",
      "iicmys : iicmys\n",
      "walisongo : walisongo\n",
      "science : science\n",
      "competition : competition\n",
      "much : much\n",
      "fuad : fuad\n",
      "saifuddin : saifuddin\n",
      "mpd : mpd\n",
      "penelitian : teliti\n",
      "kepala : kepala\n",
      "dinas : dinas\n",
      "kota : kota\n",
      "yogyakarta : yogyakarta\n",
      "kejuaran : juar\n",
      "muhammadiyah : muhammadiyah\n",
      "mipa : mipa\n",
      "dahlan : dahlan\n",
      "mengabdi : abdi\n",
      "evaluasi : evaluasi\n",
      "peraturan : atur\n",
      "tata : tata\n",
      "tertib : tertib\n",
      "kemahassiwaan : kemahassiwaan\n",
      "gendhing : gendhing\n",
      "sk : sk\n",
      "akuntansi : akuntansi\n",
      "perpanjangan : panjang\n",
      "feb : feb\n",
      "pasang : pasang\n",
      "iklan : iklan\n",
      "lowongan : lowong\n",
      "beasiswa : beasiswa\n",
      "karya : karya\n",
      "mei : mei\n",
      "kepengurusan : urus\n",
      "penerbitan : terbit\n",
      "fk : fk\n",
      "{'surat': 'surat', 'keterangan': 'terang', 'dosen': 'dosen', 'pembimbing': 'bimbing', 'tugas': 'tugas', 'lktia': 'lktia', 'fitri': 'fitri', 'indriani': 'indriani', 'mpdi': 'mpdi', 'lkmm': 'lkmm', 'menengah': 'tengah', 'kegiatan': 'giat', 'tanggap': 'tanggap', 'bencana': 'bencana', 'tim': 'tim', 'piket': 'piket', 'posko': 'posko', 'tanggep': 'tanggep', 'permohonan': 'mohon', 'izin': 'izin', 'uad': 'uad', 'awards': 'awards', 'bidang': 'bidang', 'kemahasiswaan': 'mahasiswa', 'alumni': 'alumni', 'pelatihan': 'latih', 'pembinaan': 'bina', 'kbmk': 'kbmk', '2021': '2021', 'lidm': 'lidm', 'php2d': 'php2d', 'bem': 'bem', 'fti': 'fti', 'imm': 'imm', 'farmasi': 'farmasi', 'umm': 'umm', 'championship': 'championship', 'pencak': 'pencak', 'silat': 'silat', 'virtual': 'virtual', 'panitia': 'panitia', 'por': 'por', 'bapomi': 'bapomi', 'diy': 'diy', 'lomba': 'lomba', '11th': '11th', 'airlangga': 'airlangga', 'tapak': 'tapak', 'suci': 'suci', 'international': 'international', 'open': 'open', 'bakti': 'bakti', 'formica': 'formica', 'bangsa': 'bangsa', 'sosialisasi': 'sosialisasi', 'anti': 'anti', 'intoleransi': 'intoleransi', 'kekerasan': 'keras', 'seksual': 'seksual', 'perundungan': 'rundung', 'tahap': 'tahap', 'kotnes': 'kotnes', 'robot': 'robot', 'rscuad': 'rscuad', 'kontes': 'kontes', 'lanange': 'lanange', 'jagad': 'jagad', 'aljazari': 'aljazari', 'pkm': 'pkm', 'aub': 'aub', 'cup': 'cup', '1': '1', 'jatengdiy': 'jatengdiy', 'peminjaman': 'pinjam', 'ruangan': 'ruang', 'rapat': 'rapat', 'pengurus': 'urus', 'puspresma': 'puspresma', 'ptma': 'ptma', 'inovasi': 'inovasi', 'program': 'program', 'pemberdayaan': 'daya', 'pembangunan': 'bangun', 'desa': 'desa', 'lip3d': 'lip3d', '3': '3', '2': '2', 'imss': 'imss', 'selma': 'selma', 'thalia': 'thalia', 'mtqmn': 'mtqmn', 'uny': 'uny', '198': '198', 'kreativitas': 'kreativitas', 'mahasiswa': 'mahasiswa', '2022': '2022', 'pembuatan': 'buat', 'sop': 'sop', 'permintaan': 'minta', 'barang': 'barang', 'dpm': 'dpm', 'festival': 'festival', 'nasional': 'nasional', 'alquran': 'alquran', 'hadits': 'hadits', 'survey': 'survey', 'lapangan': 'lapang', 'pendidikan': 'didik', 'anggota': 'anggota', 'muda': 'muda', 'madapala': 'madapala', 'angkatan': 'angkat', 'xxvi': 'xxvi', 'pembina': 'bina', 'center': 'center', 'ruang': 'ruang', 'fsbk': 'fsbk', 'kejuaraan': 'juara', 'bengawan': 'bengawan', 'solo': 'solo', 'national': 'national', 'turnamen': 'turnamen', 'ingco': 'ingco', 'bola': 'bola', 'voli': 'voli', 'perbaikan': 'baik', 'peralatan': 'alat', 'ukm': 'ukm', 'kopma': 'kopma', 'kampus': 'kampus', '4': '4', 'peningkatan': 'tingkat', 'kapasitas': 'kapasitas', 'organisasi': 'organisasi', 'ppk': 'ppk', 'ormawa': 'ormawa', 'penyusun': 'susun', 'proposal': 'proposal', 'gending': 'gending', 'bahana': 'bahana', 'community': 'community', 'criminal': 'criminal', 'law': 'law', 'study': 'study', 'inventaris': 'inventaris', 'alat': 'alat', 'sepak': 'sepak', 'indonesia': 'indonesia', 'krsbi': 'krsbi', 'firex': 'firex', 'pendampingan': 'damping', 'fast': 'fast', 'rekomendasi': 'rekomendasi', 'kpum': 'kpum', 'fai': 'fai', 'akses': 'akses', '24': '24', 'jam': 'jam', 'transportasi': 'transportasi', 'halaman': 'halaman', 'parkiran': 'parkir', 'utara': 'utara', 'mkmu': 'mkmu', 'konferensi': 'konferensi', 'sosiologi': 'sosiologi', 'ix': 'ix', 'nona': 'nona', 'carolina': 'carolina', 'pengelola': 'kelola', 'pendanaan': 'dana', 'kemdikbud': 'kemdikbud', 'pesta': 'pesta', 'olahraga': 'olahraga', 'perguruan': 'guru', 'seindonesia': 'indonesia', 'dasar': 'dasar', 'resimen': 'resimen', 'mahakarta': 'mahakarta', 'menwa': 'menwa', 'poros': 'poros', 'seleksi': 'seleksi', 'internal': 'internal', 'mahassiwa': 'mahassiwa', 'wirausaha': 'wirausaha', 'p2mw': 'p2mw', 'sagotra': 'sagotra', 'turgas': 'turgas', 'cabang': 'cabang', 'futsal': 'futsal', 'andalan': 'andal', 'rekrutmen': 'rekrutmen', 'pendampignan': 'pendampignan', 'gemastik': 'gemastik', 'iicmys': 'iicmys', 'walisongo': 'walisongo', 'science': 'science', 'competition': 'competition', 'much': 'much', 'fuad': 'fuad', 'saifuddin': 'saifuddin', 'mpd': 'mpd', 'penelitian': 'teliti', 'kepala': 'kepala', 'dinas': 'dinas', 'kota': 'kota', 'yogyakarta': 'yogyakarta', 'kejuaran': 'juar', 'muhammadiyah': 'muhammadiyah', 'mipa': 'mipa', 'dahlan': 'dahlan', 'mengabdi': 'abdi', 'evaluasi': 'evaluasi', 'peraturan': 'atur', 'tata': 'tata', 'tertib': 'tertib', 'kemahassiwaan': 'kemahassiwaan', 'gendhing': 'gendhing', 'sk': 'sk', 'akuntansi': 'akuntansi', 'perpanjangan': 'panjang', 'feb': 'feb', 'pasang': 'pasang', 'iklan': 'iklan', 'lowongan': 'lowong', 'beasiswa': 'beasiswa', 'karya': 'karya', 'mei': 'mei', 'kepengurusan': 'urus', 'penerbitan': 'terbit', 'fk': 'fk'}\n",
      "------------------------\n",
      "0                        [surat, terang, dosen, bimbing]\n",
      "1           [surat, tugas, lktia, fitri, indriani, mpdi]\n",
      "2                           [surat, tugas, lkmm, tengah]\n",
      "3                 [surat, tugas, giat, tanggap, bencana]\n",
      "4      [surat, tugas, tim, piket, posko, tanggep, ben...\n",
      "                             ...                        \n",
      "96            [surat, mohon, pasang, iklan, lowong, uad]\n",
      "97      [surat, mohon, beasiswa, karya, fsbk, mei, 2022]\n",
      "98                      [surat, minta, barang, bem, uad]\n",
      "99                                  [surat, mohon, urus]\n",
      "100            [surat, mohon, terbit, sk, urus, bem, fk]\n",
      "Name: judul_tokens_stemmed, Length: 101, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# stemmed\n",
    "def stemmed_wrapper(term):\n",
    "    return stemmer.stem(term)\n",
    "\n",
    "term_dict = {}\n",
    "\n",
    "for document in data['judul_tokens_WSW']:\n",
    "    for term in document:\n",
    "        if term not in term_dict:\n",
    "            term_dict[term] = ' '\n",
    "            \n",
    "print(len(term_dict))\n",
    "print(\"------------------------\")\n",
    "\n",
    "for term in term_dict:\n",
    "    term_dict[term] = stemmed_wrapper(term)\n",
    "    print(term,\":\" ,term_dict[term])\n",
    "    \n",
    "print(term_dict)\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "# apply stemmed term to dataframe\n",
    "def get_stemmed_term(document):\n",
    "    return [term_dict[term] for term in document]\n",
    "\n",
    "data['judul_tokens_stemmed'] = data['judul_tokens_WSW'].apply(get_stemmed_term)\n",
    "print(data['judul_tokens_stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e8ce026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Text_Preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "736bf169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nilai_bobot</th>\n",
       "      <th>judul_surat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>['surat', 'terang', 'dosen', 'bimbing']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['surat', 'tugas', 'lktia', 'fitri', 'indriani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['surat', 'tugas', 'lkmm', 'tengah']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>['surat', 'tugas', 'giat', 'tanggap', 'bencana']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['surat', 'tugas', 'tim', 'piket', 'posko', 't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nilai_bobot                                        judul_surat\n",
       "0            2            ['surat', 'terang', 'dosen', 'bimbing']\n",
       "1            1  ['surat', 'tugas', 'lktia', 'fitri', 'indriani...\n",
       "2            1               ['surat', 'tugas', 'lkmm', 'tengah']\n",
       "3            1   ['surat', 'tugas', 'giat', 'tanggap', 'bencana']\n",
       "4            1  ['surat', 'tugas', 'tim', 'piket', 'posko', 't..."
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surat_data = pd.read_csv(\"Text_Preprocessing.csv\", usecols=[\"nilai_bobot\", \"judul_tokens_stemmed\"])\n",
    "surat_data.columns = [\"nilai_bobot\", \"judul_surat\"]\n",
    "\n",
    "surat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ea58d0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     surat terang dosen bimbing\n",
       "1          surat tugas lktia fitri indriani mpdi\n",
       "2                        surat tugas lkmm tengah\n",
       "3               surat tugas giat tanggap bencana\n",
       "4    surat tugas tim piket posko tanggep bencana\n",
       "Name: data_join, dtype: object"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join list of token as single document string\n",
    "import ast\n",
    "\n",
    "def join_text_list(texts):\n",
    "    texts = ast.literal_eval(texts)\n",
    "    return ' '.join([text for text in texts])\n",
    "surat_data[\"data_join\"] = surat_data[\"judul_surat\"].apply(join_text_list)\n",
    "\n",
    "surat_data[\"data_join\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "2d318911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- TF-IDF on Surat Data -------\n",
      "TF-IDF  <class 'numpy.ndarray'> (101, 220)\n"
     ]
    }
   ],
   "source": [
    "# banyaknya term yang akan digunakan, \n",
    "# di pilih berdasarkan top max_features \n",
    "# yang diurutkan berdasarkan term frequency seluruh corpus\n",
    "max_features = 1000\n",
    "\n",
    "# Feature Engineering \n",
    "print (\"------- TF-IDF on Surat Data -------\")\n",
    "\n",
    "tf_idf = TfidfVectorizer(max_features=max_features, binary=True)\n",
    "tfidf_mat = tf_idf.fit_transform(surat_data[\"data_join\"]).toarray()\n",
    "\n",
    "print(\"TF-IDF \", type(tfidf_mat), tfidf_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "50246161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>surat</td>\n",
       "      <td>12.509422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>pinjam</td>\n",
       "      <td>10.712517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bem</td>\n",
       "      <td>9.161741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>uad</td>\n",
       "      <td>9.029029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tugas</td>\n",
       "      <td>8.744878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>competition</td>\n",
       "      <td>0.333165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>much</td>\n",
       "      <td>0.333165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>walisongo</td>\n",
       "      <td>0.333165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>saifuddin</td>\n",
       "      <td>0.333165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>science</td>\n",
       "      <td>0.333165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            term     weight\n",
       "188        surat  12.509422\n",
       "155       pinjam  10.712517\n",
       "28           bem   9.161741\n",
       "208          uad   9.029029\n",
       "205        tugas   8.744878\n",
       "..           ...        ...\n",
       "41   competition   0.333165\n",
       "135         much   0.333165\n",
       "216    walisongo   0.333165\n",
       "174    saifuddin   0.333165\n",
       "175      science   0.333165\n",
       "\n",
       "[220 rows x 2 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = tf_idf.get_feature_names_out()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = tfidf_mat.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "termdata = []\n",
    "for col, term in enumerate(terms):\n",
    "    termdata.append((term, sums[col] ))\n",
    "\n",
    "ranking = pd.DataFrame(termdata, columns=['term','weight'])\n",
    "ranking.sort_values('weight', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893ad50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825cf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "62f31672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nilai_bobot</th>\n",
       "      <th>judul_surat</th>\n",
       "      <th>data_join</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>['surat', 'terang', 'dosen', 'bimbing']</td>\n",
       "      <td>surat terang dosen bimbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['surat', 'tugas', 'lktia', 'fitri', 'indriani...</td>\n",
       "      <td>surat tugas lktia fitri indriani mpdi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['surat', 'tugas', 'lkmm', 'tengah']</td>\n",
       "      <td>surat tugas lkmm tengah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>['surat', 'tugas', 'giat', 'tanggap', 'bencana']</td>\n",
       "      <td>surat tugas giat tanggap bencana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['surat', 'tugas', 'tim', 'piket', 'posko', 't...</td>\n",
       "      <td>surat tugas tim piket posko tanggep bencana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>['surat', 'mohon', 'pasang', 'iklan', 'lowong'...</td>\n",
       "      <td>surat mohon pasang iklan lowong uad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>['surat', 'mohon', 'beasiswa', 'karya', 'fsbk'...</td>\n",
       "      <td>surat mohon beasiswa karya fsbk mei 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>['surat', 'minta', 'barang', 'bem', 'uad']</td>\n",
       "      <td>surat minta barang bem uad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>['surat', 'mohon', 'urus']</td>\n",
       "      <td>surat mohon urus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>['surat', 'mohon', 'terbit', 'sk', 'urus', 'be...</td>\n",
       "      <td>surat mohon terbit sk urus bem fk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nilai_bobot                                        judul_surat  \\\n",
       "0              2            ['surat', 'terang', 'dosen', 'bimbing']   \n",
       "1              1  ['surat', 'tugas', 'lktia', 'fitri', 'indriani...   \n",
       "2              1               ['surat', 'tugas', 'lkmm', 'tengah']   \n",
       "3              1   ['surat', 'tugas', 'giat', 'tanggap', 'bencana']   \n",
       "4              1  ['surat', 'tugas', 'tim', 'piket', 'posko', 't...   \n",
       "..           ...                                                ...   \n",
       "96             0  ['surat', 'mohon', 'pasang', 'iklan', 'lowong'...   \n",
       "97             0  ['surat', 'mohon', 'beasiswa', 'karya', 'fsbk'...   \n",
       "98             0         ['surat', 'minta', 'barang', 'bem', 'uad']   \n",
       "99             0                         ['surat', 'mohon', 'urus']   \n",
       "100            0  ['surat', 'mohon', 'terbit', 'sk', 'urus', 'be...   \n",
       "\n",
       "                                       data_join  \n",
       "0                     surat terang dosen bimbing  \n",
       "1          surat tugas lktia fitri indriani mpdi  \n",
       "2                        surat tugas lkmm tengah  \n",
       "3               surat tugas giat tanggap bencana  \n",
       "4    surat tugas tim piket posko tanggep bencana  \n",
       "..                                           ...  \n",
       "96           surat mohon pasang iklan lowong uad  \n",
       "97      surat mohon beasiswa karya fsbk mei 2022  \n",
       "98                    surat minta barang bem uad  \n",
       "99                              surat mohon urus  \n",
       "100            surat mohon terbit sk urus bem fk  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b9898daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul_surat</th>\n",
       "      <th>data_join</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['surat', 'terang', 'dosen', 'bimbing']</td>\n",
       "      <td>surat terang dosen bimbing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['surat', 'tugas', 'lktia', 'fitri', 'indriani...</td>\n",
       "      <td>surat tugas lktia fitri indriani mpdi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['surat', 'tugas', 'lkmm', 'tengah']</td>\n",
       "      <td>surat tugas lkmm tengah</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['surat', 'tugas', 'giat', 'tanggap', 'bencana']</td>\n",
       "      <td>surat tugas giat tanggap bencana</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['surat', 'tugas', 'tim', 'piket', 'posko', 't...</td>\n",
       "      <td>surat tugas tim piket posko tanggep bencana</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>['surat', 'mohon', 'pasang', 'iklan', 'lowong'...</td>\n",
       "      <td>surat mohon pasang iklan lowong uad</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>['surat', 'mohon', 'beasiswa', 'karya', 'fsbk'...</td>\n",
       "      <td>surat mohon beasiswa karya fsbk mei 2022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>['surat', 'minta', 'barang', 'bem', 'uad']</td>\n",
       "      <td>surat minta barang bem uad</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>['surat', 'mohon', 'urus']</td>\n",
       "      <td>surat mohon urus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>['surat', 'mohon', 'terbit', 'sk', 'urus', 'be...</td>\n",
       "      <td>surat mohon terbit sk urus bem fk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           judul_surat  \\\n",
       "0              ['surat', 'terang', 'dosen', 'bimbing']   \n",
       "1    ['surat', 'tugas', 'lktia', 'fitri', 'indriani...   \n",
       "2                 ['surat', 'tugas', 'lkmm', 'tengah']   \n",
       "3     ['surat', 'tugas', 'giat', 'tanggap', 'bencana']   \n",
       "4    ['surat', 'tugas', 'tim', 'piket', 'posko', 't...   \n",
       "..                                                 ...   \n",
       "96   ['surat', 'mohon', 'pasang', 'iklan', 'lowong'...   \n",
       "97   ['surat', 'mohon', 'beasiswa', 'karya', 'fsbk'...   \n",
       "98          ['surat', 'minta', 'barang', 'bem', 'uad']   \n",
       "99                          ['surat', 'mohon', 'urus']   \n",
       "100  ['surat', 'mohon', 'terbit', 'sk', 'urus', 'be...   \n",
       "\n",
       "                                       data_join  0  1  2  \n",
       "0                     surat terang dosen bimbing  0  0  1  \n",
       "1          surat tugas lktia fitri indriani mpdi  0  1  0  \n",
       "2                        surat tugas lkmm tengah  0  1  0  \n",
       "3               surat tugas giat tanggap bencana  0  1  0  \n",
       "4    surat tugas tim piket posko tanggep bencana  0  1  0  \n",
       "..                                           ... .. .. ..  \n",
       "96           surat mohon pasang iklan lowong uad  1  0  0  \n",
       "97      surat mohon beasiswa karya fsbk mei 2022  1  0  0  \n",
       "98                    surat minta barang bem uad  1  0  0  \n",
       "99                              surat mohon urus  1  0  0  \n",
       "100            surat mohon terbit sk urus bem fk  1  0  0  \n",
       "\n",
       "[101 rows x 5 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = pd.get_dummies(surat_data['nilai_bobot'])\n",
    "df_baru = pd.concat([surat_data, category], axis=1)\n",
    "df_baru = df_baru.drop(columns='nilai_bobot')\n",
    "df_baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "0c749b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['judul_surat', 'data_join', 0, 1, 2], dtype='object')"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baru.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "46c40f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "judul = df_baru['data_join'].values\n",
    "label = df_baru[[0,1,2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6c3d3ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "7b6e7441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    54\n",
       "0    44\n",
       "2     3\n",
       "Name: nilai_bobot, dtype: int64"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = data['nilai_bobot'].value_counts()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "25cf3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "c761ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(judul,label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "90150d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train) \n",
    "# tokenizer.fit_on_texts(X_test)\n",
    " \n",
    "sekuens_latih = tokenizer.texts_to_sequences(X_train)\n",
    "sekuens_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "maxlen = 100\n",
    "padded_latih = pad_sequences(sekuens_latih,  padding='post', maxlen=maxlen) \n",
    "padded_test = pad_sequences(sekuens_test,  padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "08e0e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "b0fd1fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "7d1f8858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 100)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_latih.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "771d4b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 100)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ebb5cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "18a665e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric = 'minkowski', p = 2)\n",
    "knn.fit(padded_latih,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "6c8e416b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(padded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f7972895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(padded_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "b3fcf7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(padded_test)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ac30a43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0de8a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.asarray(y_true).argmax(axis=1), np.asarray(y_pred).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "fa2e9a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 2  6  0]\n",
      " [ 1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "f, ax =plt.subplots(figsize = (5,5))\n",
    "sns.heatmap(cm,annot = True, linewidths= 0.5, linecolor=\"red\", fmt=\".0f\", ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "76ddfa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238095"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "fd184e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        12\n",
      "           1       1.00      0.75      0.86         8\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.85      0.81      0.83        21\n",
      "   macro avg       0.60      0.56      0.57        21\n",
      "weighted avg       0.83      0.81      0.81        21\n",
      " samples avg       0.81      0.81      0.81        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zidan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Zidan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1ac1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08f7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "606a25021e898f1e3b15dc5be68cbde6a9b25b31b1411de66e72dc9c85046bb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
